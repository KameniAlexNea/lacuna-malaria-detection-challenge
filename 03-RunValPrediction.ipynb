{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHP_ID = \"348\"\n",
    "SUBMODEL = \"cond-detr-50\" # \"cond-detr-50\"\n",
    "MODEL_PATH = f\"logs/cond-detr-50/finetuned/finetuned/checkpoint-{CHP_ID}\"\n",
    "# IMAGE_SHAPE = 1333 _Shape{IMAGE_SHAPE}\n",
    "THR = 0.01\n",
    "iou_threshold = 0.6\n",
    "FILE_NAME = f\"{SUBMODEL}_THR{THR*100:.3f}_IOU{iou_threshold:.3f}_ID{CHP_ID}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "\tAutoImageProcessor,\n",
    "\tAutoModelForObjectDetection,\n",
    "\tConditionalDetrImageProcessor,\n",
    "    ConditionalDetrForObjectDetection\n",
    ")\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision.ops import nms\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zindi_code.dataset import load_and_format\n",
    "from zindi_code import CLS_MAPPER\n",
    "\n",
    "image_folder = \"zindi_data/images\"\n",
    "\n",
    "test = load_and_format(\"zindi_data/ValDataset.csv\")\n",
    "test.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pth = MODEL_PATH\n",
    "\n",
    "image_processor: ConditionalDetrImageProcessor = AutoImageProcessor.from_pretrained(\n",
    "    model_pth\n",
    ")\n",
    "model: ConditionalDetrForObjectDetection = AutoModelForObjectDetection.from_pretrained(\n",
    "    model_pth\n",
    ")\n",
    "\n",
    "model = model.to(\n",
    "    \"cuda\"\n",
    ") # .train(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.image_transforms import center_to_corners_format\n",
    "from torch import nn\n",
    "from typing import Union, List, Tuple\n",
    "from transformers.utils.generic import TensorType\n",
    "\n",
    "n_run = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def make_predictions(images: list[Image.Image]):\n",
    "\tinputs = image_processor(images=images, return_tensors=\"pt\").to(\"cuda\")\n",
    "\t# inputs = image_processor.pad(inputs)\n",
    "\toutputs = model(**inputs)\n",
    "\ttarget_sizes = torch.tensor([image.size[::-1] for image in images])\n",
    "\treturn image_processor.post_process_object_detection(\n",
    "\t\toutputs, threshold=THR, target_sizes=target_sizes\n",
    "\t)\n",
    "\n",
    "def load_transform(path: str):\n",
    "\treturn Image.open(os.path.join(image_folder, path)).convert(\"RGB\")\n",
    "\timage = Image.open(os.path.join(image_folder, path))\n",
    "\treturn np.array(image.convert(\"RGB\"))[:, :, ::-1]\n",
    "\n",
    "def load_images(image_pths: list[str]):\n",
    "\treturn [\n",
    "\t\tload_transform(image_pth)\n",
    "\t\tfor image_pth in image_pths\n",
    "\t]\n",
    "\n",
    "\n",
    "def predicts(image_pths: list[str]):\n",
    "\timages = load_images(image_pths)\n",
    "\tresults = make_predictions(images)\n",
    "\tpredictions = []\n",
    "\tfor image_pth, result in zip(image_pths, results):\n",
    "\t\tprediction = []\n",
    "\t\tif len(result[\"boxes\"]):\n",
    "\t\t\tindices = nms(result[\"boxes\"], result[\"scores\"], iou_threshold)\n",
    "\t\t\tif not len(indices):\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tfor score, label, box in zip(\n",
    "\t\t\t\tresult[\"scores\"][indices],\n",
    "\t\t\t\tresult[\"labels\"][indices],\n",
    "\t\t\t\tresult[\"boxes\"][indices],\n",
    "\t\t\t):\n",
    "\t\t\t\tx1, y1, x2, y2 = (round(i, 2) for i in box.tolist())\n",
    "\t\t\t\tprediction.append(\n",
    "\t\t\t\t\t[\n",
    "\t\t\t\t\t\timage_pth,\n",
    "\t\t\t\t\t\tx1,\n",
    "\t\t\t\t\t\ty1,\n",
    "\t\t\t\t\t\tx2 - x1,\n",
    "\t\t\t\t\t\ty2 - y1,\n",
    "\t\t\t\t\t\tmodel.config.id2label[label.item()],\n",
    "\t\t\t\t\t\tround(score.item(), 3),\n",
    "\t\t\t\t\t]\n",
    "\t\t\t\t)\n",
    "\t\tif not len(prediction):\n",
    "\t\t\tprediction.append([image_pth] + [0, 0, 0, 0, \"NEG\", 1.])\n",
    "\t\tpredictions.extend(prediction)\n",
    "\treturn pd.DataFrame(\n",
    "\t\tpredictions, columns=[\"image_id\", \"x\", \"y\", \"w\", \"h\", \"category_id\", \"score\"]\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pths = test[\"image_id\"].unique()[:16]\n",
    "image_pths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = predicts(image_pths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"category_id\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "test_images = test[\"image_id\"].unique()\n",
    "results = [\n",
    "\tpredicts(test_images[i : i + batch_size])\n",
    "\tfor i in tqdm(\n",
    "\t\trange(0, len(test_images), batch_size), total=len(test_images) // batch_size + 1\n",
    "\t) if i < len(test_images)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.concat(results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[\"category_id\"].value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[\"score\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"zindi_data/validation/prediction_{FILE_NAME}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions.rename(columns={\"x\": \"xmin\", \"y\": \"ymin\"})\n",
    "predictions = predictions.rename(columns={\"category_id\": \"class\", \"image_id\": \"Image_ID\", \"score\": \"confidence\"})\n",
    "\n",
    "predictions[\"xmax\"] = predictions[\"xmin\"] + predictions[\"w\"]\n",
    "predictions[\"ymax\"] = predictions[\"ymin\"] + predictions[\"h\"]\n",
    "\n",
    "predictions.to_csv(f\"zindi_data/validation/prediction_{FILE_NAME}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
